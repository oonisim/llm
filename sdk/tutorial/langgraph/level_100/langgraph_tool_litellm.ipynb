{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c68d43-1024-4cdd-a283-18dbb71a9d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8a42d7f-ba8c-4040-ac0c-3a460d4be970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import operator\n",
    "from typing import (\n",
    "    Annotated, List, Dict, TypedDict, Callable, Union, Literal, Optional\n",
    ")\n",
    "\n",
    "from pydantic import (\n",
    "    BaseModel,\n",
    "    Field\n",
    ")\n",
    "from litellm import completion\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8249e274-29d0-43c4-8876-557452bf05e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab176e64-2551-4d41-bb36-07c15c9f2678",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df0e0112-8f29-4732-84f8-3fbf990eb6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_openai_key:str = os.path.expanduser('~/.openai/api_key')\n",
    "with open(path_to_openai_key, 'r', encoding='utf-8') as file:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = file.read().strip()\n",
    "\n",
    "MODEL: str = \"openai/gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49d6aaa-04d6-4f72-8194-3dfaf934ba8b",
   "metadata": {},
   "source": [
    "## Completion Model\n",
    "\n",
    "LiteLLM uses Open AI input format as the standardised schema.\n",
    "\n",
    "* [completion - Input Params](https://docs.litellm.ai/docs/completion/input)\n",
    "\n",
    "> LiteLLM accepts and translates the OpenAI Chat Completion params across all providers.\n",
    "\n",
    "See the OpenAI document for the available options.\n",
    "\n",
    "* [OpenAI API - Chat Completion](https://platform.openai.com/docs/api-reference/chat/create)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587aa639-9b86-4179-a21c-bba501c621bc",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "23da0cd1-19cb-4890-a924-9aada0ed03dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a helpful assistant to help autonomous task-execution agents.\n",
    "\n",
    "PRIMARY ROLE\n",
    "- Transform user queires into explicit, executable plans or tool calls.\n",
    "- Be meticulously step by step to derive the plans or tool calls.\n",
    "- Execute only steps that are logically justified and safe.\n",
    "- Prefer correctness and completeness over speed.\n",
    "- Think deeper and validate the thought processes taken.\n",
    "\n",
    "OPERATING RULES\n",
    "1. Never assume missing information.\n",
    "2. If required information is missing, explicitly ask for it.\n",
    "3. Do not invent facts, APIs, files, or system state.\n",
    "4. If a task exceeds your authority or tools, stop and report.\n",
    "5. If the query is unethical or can violate regulations or laws, stop and report.\n",
    "\n",
    "REASONING\n",
    "- Break tasks into explicit substeps.\n",
    "- Validate each step before proceeding.\n",
    "- Track assumptions explicitly.\n",
    "- Detect contradictions and stop if found.|\n",
    "\n",
    "TOOL USAGE\n",
    "- Use tools when you cannot handle by yourself.\n",
    "- Do not call tools speculatively.\n",
    "- Validate tool outputs before using them downstream.\n",
    "\n",
    "OUTPUT CONTRACT\n",
    "- Produce outputs that are:\n",
    "  - deterministic\n",
    "  - reproducible\n",
    "  - minimal but sufficient\n",
    "- Clearly separate:\n",
    "  - conclusions\n",
    "  - assumptions\n",
    "  - open questions\n",
    "\n",
    "FAILURE MODE\n",
    "- When uncertain, return:\n",
    "  \"Cannot proceed safely due to missing or conflicting information.\"\n",
    "- Never guess.\n",
    "\"\"\"\n",
    "\n",
    "user_message:str = \"What is the QF26 flight status today?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d128c5-266f-4361-a9fd-11dd93c7e902",
   "metadata": {},
   "source": [
    "## Model Query without Tools\n",
    "\n",
    "LLM does not know how to get NYC time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0edfcc5b-56a8-4e62-93cd-75e9f45e641b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oonisim/venv/ml/lib/python3.10/site-packages/pydantic/main.py:426: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue: Expected 10 fields but got 6 for type `Message` with value `Message(content=\"I cannot provide real-time inform...pecific_fields={'refusal': None}, annotations=[])` - serialized value may not be as expected.\n",
      "  PydanticSerializationUnexpectedValue: Expected `StreamingChoices` but got `Choices` with value `Choices(finish_reason='st...ider_specific_fields={})` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "response = completion(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message\n",
    "      }\n",
    "    ],\n",
    "    temperature=1.0,\n",
    "    max_tokens=120,\n",
    "    tool_choice=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "89684e58-c2d4-45af-83aa-347b36bb9b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-Cq8UHSj9ujxDvE7hOvgVwENaUT6FF\",\n",
      "  \"created\": 1766541717,\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"fp_deacdd5f6f\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"I cannot provide real-time information such as flight status. To find the status of QF26, you can check a reliable flight tracking website or the airline's official sources. If you need guidance on how to do this, feel free to ask!\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"tool_calls\": null,\n",
      "        \"function_call\": null,\n",
      "        \"provider_specific_fields\": {\n",
      "          \"refusal\": null\n",
      "        },\n",
      "        \"annotations\": []\n",
      "      },\n",
      "      \"provider_specific_fields\": {}\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 50,\n",
      "    \"prompt_tokens\": 300,\n",
      "    \"total_tokens\": 350,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0,\n",
      "      \"text_tokens\": null,\n",
      "      \"image_tokens\": null\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0,\n",
      "      \"text_tokens\": null,\n",
      "      \"image_tokens\": null\n",
      "    }\n",
      "  },\n",
      "  \"service_tier\": \"default\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(response.model_dump(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7ad4a3-0f29-40e6-956e-28d9b702fd1b",
   "metadata": {},
   "source": [
    "---\n",
    "# Tools\n",
    "\n",
    "## Defining Tool Schema\n",
    "\n",
    "Suppose using [Tavily - Search](https://docs.tavily.com/sdk/python/reference#tavily-search) as a general search tool such as getting time or weather of a city. We need to tell LLM of the schema that Tavily Search accepts. Find the available parameters from the API document or using [Tavily Search Playground](https://app.tavily.com/home). Then LiteLLM can get the Tool Schema from SearchTool.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f7282e8f-622c-4ac6-8bc4-1488b3fd3340",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchTool(BaseModel):\n",
    "    # DocString tells LLM what this tool is for.\n",
    "    \"\"\"Search the web for general topics such as time, news, weather, events.\"\"\"\n",
    "    query: str = Field(description=\"The search query to look up\")\n",
    "\n",
    "    #--------------------------------------------------------------------------------\n",
    "    # Attributes of Tavily Search API (https://docs.tavily.com/sdk/python/reference).\n",
    "    # LLM can genrate the arguments based on these information.\n",
    "    #--------------------------------------------------------------------------------\n",
    "    topic: Literal[\"general\", \"news\", \"finance\"] = Field(\n",
    "        default=\"general\",\n",
    "        description=\"Category of search. Use 'news' for current events/politics, 'finance' for market data.\"\n",
    "    )\n",
    "    \n",
    "    search_depth: Literal[\"basic\", \"advanced\"] = Field(\n",
    "        default=\"basic\",\n",
    "        description=\"Use 'basic' for quick facts. Use 'advanced' for complex queries needing more context.\"\n",
    "    )\n",
    "    \n",
    "    time_range: Optional[Literal[\"day\", \"week\", \"month\", \"year\"]] = Field(\n",
    "        default=None,\n",
    "        description=\"Filter results by publication date. Especially useful with topic='news'.\"\n",
    "    )\n",
    "    \n",
    "    max_results: int = Field(\n",
    "        default=5, ge=1, le=10,\n",
    "        description=\"Number of search results to return.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "14e641cb-2ce2-4312-bb41-f77faa3565da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"description\": \"Search the web for general topics such as time, news, weather, events.\",\n",
      "  \"properties\": {\n",
      "    \"query\": {\n",
      "      \"description\": \"The search query to look up\",\n",
      "      \"title\": \"Query\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"topic\": {\n",
      "      \"default\": \"general\",\n",
      "      \"description\": \"Category of search. Use 'news' for current events/politics, 'finance' for market data.\",\n",
      "      \"enum\": [\n",
      "        \"general\",\n",
      "        \"news\",\n",
      "        \"finance\"\n",
      "      ],\n",
      "      \"title\": \"Topic\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"search_depth\": {\n",
      "      \"default\": \"basic\",\n",
      "      \"description\": \"Use 'basic' for quick facts. Use 'advanced' for complex queries needing more context.\",\n",
      "      \"enum\": [\n",
      "        \"basic\",\n",
      "        \"advanced\"\n",
      "      ],\n",
      "      \"title\": \"Search Depth\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"time_range\": {\n",
      "      \"anyOf\": [\n",
      "        {\n",
      "          \"enum\": [\n",
      "            \"day\",\n",
      "            \"week\",\n",
      "            \"month\",\n",
      "            \"year\"\n",
      "          ],\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"null\"\n",
      "        }\n",
      "      ],\n",
      "      \"default\": null,\n",
      "      \"description\": \"Filter results by publication date. Especially useful with topic='news'.\",\n",
      "      \"title\": \"Time Range\"\n",
      "    },\n",
      "    \"max_results\": {\n",
      "      \"default\": 5,\n",
      "      \"description\": \"Number of search results to return.\",\n",
      "      \"maximum\": 10,\n",
      "      \"minimum\": 1,\n",
      "      \"title\": \"Max Results\",\n",
      "      \"type\": \"integer\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"query\"\n",
      "  ],\n",
      "  \"title\": \"SearchTool\",\n",
      "  \"type\": \"object\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(SearchTool.model_json_schema(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef39125-2792-4447-bdca-81061188ed3e",
   "metadata": {},
   "source": [
    "## Model Query with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "21726c8f-5fe5-40ba-b371-cf26a7906aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tavily_key:str = os.path.expanduser('~/.tavily/api_key')\n",
    "with open(path_to_tavily_key, 'r', encoding='utf-8') as file:\n",
    "    os.environ[\"TAVILY_API_KEY\"] = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6547f230-d88e-437f-9cdd-2b0ca3f47add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oonisim/venv/ml/lib/python3.10/site-packages/pydantic/main.py:426: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue: Expected 10 fields but got 6 for type `Message` with value `Message(content='To provide the status of QF26 fli...pecific_fields={'refusal': None}, annotations=[])` - serialized value may not be as expected.\n",
      "  PydanticSerializationUnexpectedValue: Expected `StreamingChoices` but got `Choices` with value `Choices(finish_reason='to...ider_specific_fields={})` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "response = completion(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message\n",
    "      }\n",
    "    ],\n",
    "    temperature=1.0,\n",
    "    max_tokens=120,\n",
    "    # --------------------------------------------------------------------------------\n",
    "    # Provide Tools\n",
    "    # --------------------------------------------------------------------------------\n",
    "    tool_choice=\"auto\",\n",
    "    tools = [{\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": SearchTool.__name__,\n",
    "            \"description\": SearchTool.__doc__,\n",
    "            \"parameters\": SearchTool.model_json_schema()\n",
    "        }\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bb4fbc18-5ff6-4143-828c-406fe8dd093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-Cq8UJhVCTyoPjVxQJjCWORDVtRrvP\",\n",
      "  \"created\": 1766541719,\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"fp_deacdd5f6f\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"tool_calls\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"To provide the status of QF26 flight today, I need to perform a search. I will proceed with searching for the current status of this flight.\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"function\": {\n",
      "              \"arguments\": \"{\\\"query\\\":\\\"QF26 flight status today\\\",\\\"topic\\\":\\\"general\\\",\\\"search_depth\\\":\\\"basic\\\"}\",\n",
      "              \"name\": \"SearchTool\"\n",
      "            },\n",
      "            \"id\": \"call_G5Iv5254qonptStZOaVqul4D\",\n",
      "            \"type\": \"function\"\n",
      "          }\n",
      "        ],\n",
      "        \"function_call\": null,\n",
      "        \"provider_specific_fields\": {\n",
      "          \"refusal\": null\n",
      "        },\n",
      "        \"annotations\": []\n",
      "      },\n",
      "      \"provider_specific_fields\": {}\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 60,\n",
      "    \"prompt_tokens\": 533,\n",
      "    \"total_tokens\": 593,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0,\n",
      "      \"text_tokens\": null,\n",
      "      \"image_tokens\": null\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0,\n",
      "      \"text_tokens\": null,\n",
      "      \"image_tokens\": null\n",
      "    }\n",
      "  },\n",
      "  \"service_tier\": \"default\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(response.model_dump(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f025a8e3-f194-4231-8348-b93691668c01",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bdafa8-3921-4ffb-8a3c-40eabd4ca5ee",
   "metadata": {},
   "source": [
    "# LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0a7a12-365e-4a06-9ca6-cbba3d320cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e09a5b2-ea8f-458b-a077-81cffc843794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b701e5-0072-476d-a4ab-1e483f635fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddacafc2-237d-44c9-be50-2c711cb6b5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5164177b-1a85-4319-8d54-3334a8aff693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537489b7-2627-408d-9a7d-82b986fcc0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09828088-02b8-43dd-8c91-2b593de10176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6701194a-848a-4159-a3ed-16a241dacb0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AgentState' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_tool\u001b[39m(state: \u001b[43mAgentState\u001b[49m):\n\u001b[1;32m      2\u001b[0m     last_msg \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mmessages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m     tool_call \u001b[38;5;241m=\u001b[39m last_msg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AgentState' is not defined"
     ]
    }
   ],
   "source": [
    "def call_tool(state: AgentState):\n",
    "    last_msg = state.messages[-1]\n",
    "    tool_call = last_msg[\"tool_calls\"][0]\n",
    "    \n",
    "    # Extract arguments - these now include topic, search_depth, etc.\n",
    "    args = json.loads(tool_call[\"function\"][\"arguments\"])\n",
    "    \n",
    "    # 5. DYNAMIC TAVILY CALL\n",
    "    # Passing **args allows Tavily to receive topic, time_range, etc. automatically\n",
    "    search_data = tavily.search(**args)\n",
    "    \n",
    "    content = \"\\n\".join([\n",
    "        f\"Source: {r['title']}\\nURL: {r['url']}\\nContent: {r['content']}\\n---\" \n",
    "        for r in search_data['results']\n",
    "    ])\n",
    "    \n",
    "    return {\"messages\": [{\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": tool_call[\"id\"],\n",
    "        \"name\": \"SearchTool\",\n",
    "        \"content\": content\n",
    "    }]}\n",
    "\n",
    "# 6. ROUTER & GRAPH\n",
    "def router(state: AgentState) -> Literal[\"call_tool\", \"__end__\"]:\n",
    "    last_msg = state.messages[-1]\n",
    "    return \"call_tool\" if last_msg.get(\"tool_calls\") else \"__end__\"\n",
    "\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"llm\", call_model)\n",
    "builder.add_node(\"call_tool\", call_tool)\n",
    "builder.add_edge(START, \"llm\")\n",
    "builder.add_conditional_edges(\"llm\", router)\n",
    "builder.add_edge(\"call_tool\", \"llm\")\n",
    "app = builder.compile()\n",
    "\n",
    "# 7. EXECUTION\n",
    "# Example: Try asking for \"Latest news about Bitcoin today\" \n",
    "# to see the LLM choose topic=\"news\" and time_range=\"day\".\n",
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"What are the top news headlines in AI from the last week?\"}]}\n",
    "\n",
    "for event in app.stream(inputs, stream_mode=\"values\"):\n",
    "    last_msg = event[\"messages\"][-1]\n",
    "    role = last_msg[\"role\"].upper()\n",
    "    \n",
    "    # Display logic to show tool parameters used\n",
    "    if \"tool_calls\" in last_msg:\n",
    "        params = json.loads(last_msg[\"tool_calls\"][0][\"function\"][\"arguments\"])\n",
    "        print(f\"\\n--- {role} (Calling Search with params: {params}) ---\")\n",
    "    else:\n",
    "        print(f\"\\n--- {role} ---\")\n",
    "        print(last_msg.get(\"content\") or \"Processing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f280a58e-99a1-4b1f-b75c-12ab3bf6eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. EXECUTION\n",
    "inputs = {\"messages\": [{\"role\": \"user\", \"content\": \"What are the top news headlines in AI from the last week?\"}]}\n",
    "\n",
    "for event in app.stream(inputs, stream_mode=\"values\"):\n",
    "    last_msg = event[\"messages\"][-1]\n",
    "    \n",
    "    # Check if it's a dictionary (from our nodes) or a LiteLLM object\n",
    "    role = last_msg.get(\"role\", \"assistant\").upper() if isinstance(last_msg, dict) else last_msg.role.upper()\n",
    "    \n",
    "    # Robust display logic\n",
    "    tool_calls = last_msg.get(\"tool_calls\") if isinstance(last_msg, dict) else getattr(last_msg, \"tool_calls\", None)\n",
    "\n",
    "    if tool_calls:\n",
    "        # tool_calls[0] is an object, but function.arguments is a string\n",
    "        first_call = tool_calls[0]\n",
    "        # Handle both object-style and dict-style access\n",
    "        args_str = first_call[\"function\"][\"arguments\"] if isinstance(first_call, dict) else first_call.function.arguments\n",
    "        params = json.loads(args_str)\n",
    "        print(f\"\\n--- {role} (Calling Search with params: {params}) ---\")\n",
    "    else:\n",
    "        content = last_msg.get(\"content\") if isinstance(last_msg, dict) else getattr(last_msg, \"content\", \"\")\n",
    "        print(f\"\\n--- {role} ---\")\n",
    "        if content:\n",
    "            print(content)\n",
    "        else:\n",
    "            print(\"Processing...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
