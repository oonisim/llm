{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "847de34b-45bb-4c5f-81c3-d684e2628809",
   "metadata": {},
   "source": [
    "# LangGrpah Chatbot\n",
    "\n",
    "* Real Pyton - [Build Stateful AI Agents in Python](https://realpython.com/langgraph-python/)\n",
    "\n",
    "> LangGraph expands LangChainâ€™s capabilities by providing tools to build complex LLM workflows with state, conditional edges, and cycles.\n",
    "\n",
    "\n",
    "* [docs/tutorials/get-started](https://github.com/langchain-ai/langgraph/tree/main/docs/docs/tutorials/get-started)\n",
    "\n",
    "> To get acquainted with LangGraph's key concepts and features, complete the following LangGraph basics tutorials series:\n",
    "> \n",
    "> 1. Build a basic chatbot\n",
    "> 2. Add tools\n",
    "> 3. Add memory\n",
    "> 4. Add human-in-the-loop controls\n",
    "> 5. Customize state\n",
    "> 6. Time travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be572eff-d932-479f-aa9e-ca37649ea842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Annotated, List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d3fc920-71a5-4002-8385-bf34997e00ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"OpenAI chat model listing and connection test using LangChain.\n",
    "\n",
    "This script:\n",
    "1. Lists all chat-compatible OpenAI models.\n",
    "2. Picks the latest GPT model suitable for chat.\n",
    "3. Tests the selected model with a simple prompt.\n",
    "\n",
    "Requires:\n",
    "    - langchain-openai\n",
    "    - langchain-core\n",
    "    - openai >= 1.0.0\n",
    "\n",
    "Environment:\n",
    "    OPENAI_API_KEY must be set.\n",
    "\"\"\"\n",
    "def list_openai_models() -> List[str]:\n",
    "    \"\"\"List all chat-completion compatible OpenAI models.\n",
    "\n",
    "    Returns:\n",
    "        List of chat-compatible model names.\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    try:\n",
    "        response = openai.models.list()\n",
    "        models = [model for model in response.data]\n",
    "        return models\n",
    "    except Exception as error:\n",
    "        print(f\"Failed to list models: {error}\")\n",
    "        return []\n",
    "\n",
    "def list_openai_chat_models() -> List[str]:\n",
    "    \"\"\"List all chat-completion compatible OpenAI models.\n",
    "\n",
    "    Returns:\n",
    "        List of chat-compatible model names.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.models.list()\n",
    "        chat_models = []\n",
    "        for model in response.data:\n",
    "            if \"chat\" in model.id.lower():\n",
    "                chat_models.append(model.id)\n",
    "        print(\"Available Chat Models:\")\n",
    "        return chat_models\n",
    "    except Exception as error:\n",
    "        print(f\"Failed to list models: {error}\")\n",
    "        return []\n",
    "\n",
    "def test_openai_connection(model) -> None:\n",
    "    \"\"\"Test OpenAI connection using the latest chat-compatible model.\"\"\"\n",
    "    # chat_models = list_chat_models()\n",
    "    if not model:\n",
    "        print(\"No chat-compatible models available.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nTesting model: {model}\\n\")\n",
    "\n",
    "    try:\n",
    "        llm = ChatOpenAI(model=model, temperature=1.0)\n",
    "        prompt_text = \"What is the capital of France? Respond with only the name of the city.\"\n",
    "        messages = [HumanMessage(content=prompt_text)]\n",
    "        response = llm.invoke(messages)\n",
    "\n",
    "        if response.content.strip().lower() == \"paris\":\n",
    "            print(\"CONNECTION SUCCESSFUL!\")\n",
    "            print(f\"Model ({llm.model_name}) responded correctly: {response.content}\")\n",
    "        else:\n",
    "            print(\"CONNECTION SUCCEEDED, but response was unexpected.\")\n",
    "            print(f\"Model Response: {response.content}\")\n",
    "\n",
    "    except Exception as error:\n",
    "        print(\"CONNECTION FAILED!\")\n",
    "        print(f\"Error Details: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb34b982-6cc7-4dce-aebc-76dbbe49aa5d",
   "metadata": {},
   "source": [
    "# Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f85df6c4-0ccb-4bd3-b2ab-814ec53acf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL: str = 'gpt-4.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64350552-f94c-4e2b-8b49-42448b0e588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_openai_key:str = os.path.expanduser('~/.openai/api_key')\n",
    "with open(path_to_openai_key, 'r', encoding='utf-8') as file:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16723d1e-1ad7-472c-bc88-e793aff11d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing model: gpt-4.1\n",
      "\n",
      "CONNECTION SUCCESSFUL!\n",
      "Model (gpt-4.1) responded correctly: Paris\n"
     ]
    }
   ],
   "source": [
    "test_openai_connection(MODEL)\n",
    "llm = init_chat_model(f\"openai:{MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea499b4-ec6c-4daf-aef8-129c80e935d7",
   "metadata": {},
   "source": [
    "# Chat Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894a7e53-7dfb-4a2f-8a79-e05edd9ea5e1",
   "metadata": {},
   "source": [
    "## State Machine Memory\n",
    "A ```StateGraph``` object defines the application as a graph. First step is to define its ```State``` object. The ```State``` includes the graph's schema and reducer functions that handle state updates. In our example, State is a schema with one key: messages. The reducer function is used to append new messages to the list instead of overwriting it. Keys without a reducer annotation will overwrite previous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b736285-5b7e-4c14-8c67-f24e915ba1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    \"\"\"Chat State (message history)\n",
    "    \"\"\"\n",
    "    messages: Annotated[\n",
    "        list, \n",
    "        add_messages\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c646aa-2f55-4682-8833-d65c88291fc3",
   "metadata": {},
   "source": [
    "## ChatBot Function as a Graph Node\n",
    "\n",
    "Add a ```chatbot``` function as a node to the graph. Nodes represent units of work and are typically regular functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf68bf2-b787-4081-919b-d88771f2349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    \"\"\"Chat Bot Function which is the basic pattern for all LangGraph node functions.\n",
    "    The add_messages function in the State instance will append the LLM's response messages.\n",
    "\n",
    "    Args:\n",
    "        state: chat history\n",
    "\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# The first argument is the unique node name and The second argument is \n",
    "# the function or object that will be called whenever he node is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b8a6208-92b2-4c06-a5c6-3b3ecf59ff12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10685bc50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Builder Pattern (GoF), not Factory pattern as you need to specify how to build step by step.\n",
    "app_graph_builder = StateGraph(State)\n",
    "\n",
    "# The first argument is the unique node name. The second argument is \n",
    "# the function or object that will be called whenever the node is used.\n",
    "app_graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d46b80f-63e1-4b68-82b1-7b93bbe8048c",
   "metadata": {},
   "source": [
    "## Add START entry point to the ```chatbot``` node in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5298915f-394a-4103-889c-d484fd0bf4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10685bc50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaab0ed-43fd-447d-a971-ca832565146c",
   "metadata": {},
   "source": [
    "## Add END exit point to from the ```chatbot``` node in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2846c73-00b2-4bc9-9cd4-4aa4696d8c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10685bc50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bdc249-224d-4c17-a1e7-e03ccba12a31",
   "metadata": {},
   "source": [
    "## Compile the Greaph\n",
    "\n",
    "Creates a ```CompiledGraph```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d95d7e0-88aa-4a85-8305-8027b5458308",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = app_graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1702abce-cfb8-40ef-be0d-0ba38080633b",
   "metadata": {},
   "source": [
    "### Verify the ChatBot as a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90b6eba6-0e5b-456f-ba02-56c54b38699d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to reach https://mermaid.ink API while trying to render your graph. Status code: 400.\n",
      "\n",
      "To resolve this issue:\n",
      "1. Check your internet connection and try again\n",
      "2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n",
      "3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`\n"
     ]
    }
   ],
   "source": [
    "# Using https://mermaid.ink/\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60218a55-a9ea-4c32-b242-f5ee89b455f3",
   "metadata": {},
   "source": [
    "# Run Chat Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8731bf14-2132-422e-b92f-82f656c1309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  who is Elon musk?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: **Elon Musk** is a prominent entrepreneur, engineer, and inventor known for founding and leading several groundbreaking companies. He was born on June 28, 1971, in Pretoria, South Africa. Musk is most famously known as the CEO and lead designer of **SpaceX**, CEO and product architect of **Tesla, Inc.**, owner and CTO of **X Corp.** (formerly known as Twitter), and the founder of companies like **The Boring Company**, **Neuralink**, and **OpenAI** (he was a co-founder but is no longer directly involved).\n",
      "\n",
      "Here are a few highlights about Elon Musk:\n",
      "\n",
      "- **SpaceX**: Musk founded SpaceX in 2002 with the goal of reducing space transportation costs and enabling the colonization of Mars. SpaceX has developed rockets like Falcon 1, Falcon 9, Falcon Heavy, and the Starship.\n",
      "- **Tesla, Inc.**: He became involved with Tesla in 2004, soon after its founding, and helped popularize electric vehicles, battery storage, and solar energy products.\n",
      "- **Twitter/X**: Musk acquired Twitter in 2022, later rebranding it to X, and has since implemented significant changes to the platform.\n",
      "- **The Boring Company**: Focused on tunnel construction and infrastructure projects to address urban transportation challenges.\n",
      "- **Neuralink**: Developing brain-computer interface technology.\n",
      "- **OpenAI**: Co-founded in 2015 to promote and develop friendly artificial intelligence.\n",
      "\n",
      "**Musk** is known for his ambitious vision of the future, including the colonization of Mars, transitioning the world to sustainable energy, and integrating artificial intelligence with the human brain. He is a polarizing figure, admired for his innovation but often criticized for his management style and controversial public statements.\n",
      "\n",
      "As of 2024, Elon Musk is considered one of the richest people in the world and remains a major influencer in technology, transportation, and energy sectors.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except Exception as e:\n",
    "        print(f\"failed due to {e}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b42d98-7ba1-4221-8b00-1628367fb2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fecb01-0810-457b-b13e-a1adfa8f3e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
