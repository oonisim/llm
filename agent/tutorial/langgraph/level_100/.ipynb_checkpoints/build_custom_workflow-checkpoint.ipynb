{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "847de34b-45bb-4c5f-81c3-d684e2628809",
   "metadata": {},
   "source": [
    "# LangGrpah \n",
    "\n",
    "* [Build a custom workflow](https://langchain-ai.github.io/langgraph/concepts/why-langgraph/)\n",
    "\n",
    "> To get acquainted with LangGraph's key concepts and features, complete the following LangGraph basics tutorials series:\n",
    "> \n",
    "> 1. Build a basic chatbot\n",
    "> 2. Add tools\n",
    "> 3. Add memory\n",
    "> 4. Add human-in-the-loop controls\n",
    "> 5. Customize state\n",
    "> 6. Time travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be572eff-d932-479f-aa9e-ca37649ea842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27612564-5999-4441-922b-093833dfcab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# --- 1. Set the API Key (Crucial Step) ---\n",
    "# Ensure your OpenAI API key is set as an environment variable.\n",
    "# LangChain will automatically look for the OPENAI_API_KEY variable.\n",
    "#\n",
    "# If you need to set it directly in the script for testing (NOT recommended for production):\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_SECRET_KEY\"\n",
    "\n",
    "# --- 2. Define the Connection Test Function ---\n",
    "def test_openai_connection():\n",
    "    try:\n",
    "        # Initialize the LangChain ChatOpenAI model\n",
    "        # Using a fast, standard model like gpt-3.5-turbo\n",
    "        llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "        # Define a simple, non-creative prompt\n",
    "        prompt_text = \"What is the capital of France? Respond with only the name of the city.\"\n",
    "        \n",
    "        # Create a list of messages for the model\n",
    "        messages = [HumanMessage(content=prompt_text)]\n",
    "\n",
    "        # --- 3. Execute the API Call ---\n",
    "        response = llm.invoke(messages)\n",
    "        \n",
    "        # --- 4. Check the Response ---\n",
    "        if response.content.strip().lower() == \"paris\":\n",
    "            print(\"✅ CONNECTION SUCCESSFUL!\")\n",
    "            print(f\"Model ({llm.model_name}) responded correctly: {response.content}\")\n",
    "        else:\n",
    "            print(\"⚠️ CONNECTION SUCCEEDED, but response was unexpected.\")\n",
    "            print(f\"Model Response: {response.content}\")\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"❌ ERROR: LangChain is not installed.\")\n",
    "        print(\"Please install required libraries: `pip install langchain-openai langchain-core`\")\n",
    "    except Exception as e:\n",
    "        print(\"❌ CONNECTION FAILED!\")\n",
    "        # Common errors here include: AuthenticationError (bad API key), \n",
    "        # APIConnectionError (network/proxy issue), or RateLimitError.\n",
    "        print(f\"Error Details: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb34b982-6cc7-4dce-aebc-76dbbe49aa5d",
   "metadata": {},
   "source": [
    "# Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64350552-f94c-4e2b-8b49-42448b0e588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_openai_key:str = os.path.expanduser('~/.openai/api_key')\n",
    "with open(path_to_openai_key, 'r', encoding='utf-8') as file:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16723d1e-1ad7-472c-bc88-e793aff11d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"openai:gpt-4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "306e55e0-c49f-4d7f-bae9-5da093c1e463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CONNECTION SUCCESSFUL!\n",
      "Model (gpt-3.5-turbo) responded correctly: Paris\n"
     ]
    }
   ],
   "source": [
    "test_openai_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea499b4-ec6c-4daf-aef8-129c80e935d7",
   "metadata": {},
   "source": [
    "# Chat Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894a7e53-7dfb-4a2f-8a79-e05edd9ea5e1",
   "metadata": {},
   "source": [
    "## State Machine Memory\n",
    "A ```StateGraph``` object defines the state machine for the chat bot. When defining a graph, the first step is to define its State. The State includes the graph's schema and reducer functions that handle state updates. In our example, State is a schema with one key: messages. The reducer function is used to append new messages to the list instead of overwriting it. Keys without a reducer annotation will overwrite previous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b736285-5b7e-4c14-8c67-f24e915ba1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    \"\"\"Chat State (message history)\n",
    "    \"\"\"\n",
    "    messages: Annotated[\n",
    "        list, \n",
    "        add_messages    # from langgraph.graph.message import add_messages\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c646aa-2f55-4682-8833-d65c88291fc3",
   "metadata": {},
   "source": [
    "## ChatBot Function as a Graph Node\n",
    "\n",
    "Add a ```chatbot``` function as a node to the graph. Nodes represent units of work and are typically regular functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf68bf2-b787-4081-919b-d88771f2349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    \"\"\"Chat Bot Function which is the basic pattern for all LangGraph node functions.\n",
    "    The add_messages function in the State instance will append the LLM's response messages.\n",
    "\n",
    "    Args:\n",
    "        state: chat history\n",
    "\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# The first argument is the unique node name and The second argument is \n",
    "# the function or object that will be called whenever he node is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b8a6208-92b2-4c06-a5c6-3b3ecf59ff12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10b8b5840>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# The first argument is the unique node name. The second argument is \n",
    "# the function or object that will be called whenever the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d46b80f-63e1-4b68-82b1-7b93bbe8048c",
   "metadata": {},
   "source": [
    "## Add START entry point to the ```chatbot``` node in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5298915f-394a-4103-889c-d484fd0bf4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10b8b5840>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaab0ed-43fd-447d-a971-ca832565146c",
   "metadata": {},
   "source": [
    "## Add END exit point to from the ```chatbot``` node in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2846c73-00b2-4bc9-9cd4-4aa4696d8c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10b8b5840>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bdc249-224d-4c17-a1e7-e03ccba12a31",
   "metadata": {},
   "source": [
    "## Compile the Greaph\n",
    "\n",
    "Creates a ```CompiledGraph```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d95d7e0-88aa-4a85-8305-8027b5458308",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1702abce-cfb8-40ef-be0d-0ba38080633b",
   "metadata": {},
   "source": [
    "### Verify the ChatBot as a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90b6eba6-0e5b-456f-ba02-56c54b38699d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 204.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m display(Image(\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m~/venv/ml/lib/python3.10/site-packages/langchain_core/runnables/graph.py:693\u001b[0m, in \u001b[0;36mGraph.draw_mermaid_png\u001b[0;34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_mermaid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[1;32m    687\u001b[0m mermaid_syntax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_mermaid(\n\u001b[1;32m    688\u001b[0m     curve_style\u001b[38;5;241m=\u001b[39mcurve_style,\n\u001b[1;32m    689\u001b[0m     node_colors\u001b[38;5;241m=\u001b[39mnode_colors,\n\u001b[1;32m    690\u001b[0m     wrap_label_n_words\u001b[38;5;241m=\u001b[39mwrap_label_n_words,\n\u001b[1;32m    691\u001b[0m     frontmatter_config\u001b[38;5;241m=\u001b[39mfrontmatter_config,\n\u001b[1;32m    692\u001b[0m )\n\u001b[0;32m--> 693\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/ml/lib/python3.10/site-packages/langchain_core/runnables/graph_mermaid.py:293\u001b[0m, in \u001b[0;36mdraw_mermaid_png\u001b[0;34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[0m\n\u001b[1;32m    287\u001b[0m     img_bytes \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    288\u001b[0m         _render_mermaid_using_pyppeteer(\n\u001b[1;32m    289\u001b[0m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[1;32m    290\u001b[0m         )\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m draw_method \u001b[38;5;241m==\u001b[39m MermaidDrawMethod\u001b[38;5;241m.\u001b[39mAPI:\n\u001b[0;32m--> 293\u001b[0m     img_bytes \u001b[38;5;241m=\u001b[39m \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     supported_methods \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "File \u001b[0;32m~/venv/ml/lib/python3.10/site-packages/langchain_core/runnables/graph_mermaid.py:450\u001b[0m, in \u001b[0;36m_render_mermaid_using_api\u001b[0;34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# For other status codes, fail immediately\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour graph. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m     ) \u001b[38;5;241m+\u001b[39m error_msg_suffix\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (requests\u001b[38;5;241m.\u001b[39mRequestException, requests\u001b[38;5;241m.\u001b[39mTimeout) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attempt \u001b[38;5;241m<\u001b[39m max_retries:\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;66;03m# Exponential backoff with jitter\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 204.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
     ]
    }
   ],
   "source": [
    "# Using https://mermaid.ink/\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60218a55-a9ea-4c32-b242-f5ee89b455f3",
   "metadata": {},
   "source": [
    "# Run Chat Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8731bf14-2132-422e-b92f-82f656c1309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is langgraph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: **LangGraph** is a framework for building **stateful, multi-actor applications** on top of **Large Language Models (LLMs)**. It was created by the team behind [LangChain](https://www.langchain.com/), a popular library for developing applications that use LLMs.\n",
      "\n",
      "### What does LangGraph do?\n",
      "LangGraph provides a way to design applications as **graphs**, where each node is an \"actor\" (an LLM, a tool, an agent, or your own function), and edges control the flow of information and state. Unlike linear chains (like in classic LangChain), LangGraph enables **complex interactions**, **loops**, and **memory/stateful reasoning**.\n",
      "\n",
      "### Key concepts\n",
      "\n",
      "- **Actors:** Nodes in the graph that can process data—these are usually functions, LLMs, or agents.\n",
      "- **Edges:** Connections indicating how the next actor is chosen, often based on state or output.\n",
      "- **State:** LangGraph lets you maintain and update state as the graph executes. This enables multi-step reasoning and memory.\n",
      "\n",
      "### Why use LangGraph?\n",
      "\n",
      "- **Flexible control flow:** Build complex apps, automate decisions, handle loops, branching, and more.\n",
      "- **Multi-agent workflows:** Easily create applications with multiple LLMs or agents collaborating and passing information.\n",
      "- **Stateful reasoning:** Unlike simple chains, LangGraph lets you carry, update, and use state throughout the workflow.\n",
      "\n",
      "### Example Use Cases\n",
      "\n",
      "- **Multi-agent chatbots:** Different LLMs (agents) assigned to different roles, working together on a user query.\n",
      "- **Workflow automation:** Complex business logic with conditional steps and memory.\n",
      "- **Iterative tasks:** Applications that need to loop or retry steps based on intermediate results.\n",
      "\n",
      "### Related Links\n",
      "\n",
      "- [LangGraph Documentation](https://langgraph.readthedocs.io/)\n",
      "- [LangGraph GitHub](https://github.com/langchain-ai/langgraph)\n",
      "- [Announcement Video (YouTube)](https://www.youtube.com/watch?v=RykboE9SHvY)\n",
      "\n",
      "---\n",
      "\n",
      "**In summary:**  \n",
      "LangGraph is a framework that lets you build sophisticated, stateful applications using LLMs—where you define logic as a graph of actors and transitions, enabling powerful multi-step and multi-agent interactions.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except Exception as e:\n",
    "        print(f\"failed due to {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b42d98-7ba1-4221-8b00-1628367fb2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fecb01-0810-457b-b13e-a1adfa8f3e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
